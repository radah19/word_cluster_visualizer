# Based off Peter Norvig's Spellchecker
# http://norvig.com/spell-correct.html

import nltk
nltk.download('words')
from nltk.corpus import words as nltk_words

from collections import Counter

class AffixSpellChecker:
    def __init__(self) -> None:
        self.word_set = nltk_words.words() #filter(lambda x: len(x) >= 9, nltk_words.words())
        self.word_freq = Counter(self.word_set)

        # Exhaustive suffix and prefix list generated by AI
        self.prefixes = {
            'un', 'in', 're', 'dis', 'over', 'under', 'pre', 'post', 'non', 'sub',
            'inter', 'trans', 'super', 'semi', 'anti', 'mid', 'mis', 'out', 'co',
            'a', 'ab', 'ad', 'be', 'bi', 'com', 'con', 'de', 'em', 'en', 'ex', 'fore',
            'hyper', 'ir', 'macro', 'mal', 'mega', 'micro', 'mini', 'mono',
            'multi', 'neo', 'omni', 'para', 'per', 'poly', 'pro', 'proto', 'pseudo',
            'retro', 'self', 'tele', 'tri', 'ultra', 'uni', 'vice'
        }
        self.suffixes = {
            's', 'es', 'ing', 'ed', 'd', 'er', 'est', 'ful', 'ness', 'less', 'ly', 'able', 'ible',
            'al', 'ial', 'ic', 'ical', 'ious', 'ous', 'ive', 'ative', 'ment', 'ion',
            'ation', 'ity', 'ty', 'ize', 'ise', 'dom', 'ship', 'hood', 'ish', 'fold',
            'age', 'an', 'ance', 'ancy', 'ant', 'arium', 'ary', 'ate', 'cide', 'cracy',
            'crat', 'cy', 'cycle', 'dom', 'ee', 'en', 'ence', 'ency', 'ent', 'ery',
            'ese', 'esque', 'ess', 'et', 'ette', 'fication', 'fy', 'gram', 'graph',
            'graphy', 'iatric', 'ible', 'ic', 'ical', 'ics', 'id', 'ide', 'ify', 'ile',
            'ina', 'ine', 'ing', 'ion', 'ism', 'ist', 'ite', 'itis', 'ity', 'ium', 'ive',
            'ization', 'ize', 'let', 'like', 'ling', 'log', 'logy', 'ly', 'meter',
            'metry', 'most', 'nomy', 'oid', 'ology', 'oma', 'onym', 'opia', 'opsy',
            'or', 'ory', 'osis', 'path', 'pathy', 'phile', 'phobia', 'phone', 'phyte',
            'plegia', 'plegic', 'pnea', 'scope', 'scopy', 'scribe', 'script', 'sect',
            'some', 'sophy', 'th', 'tion', 'tome', 'trophy', 'tude', 'ty', 'ular',
            'uous', 'ure', 'ward', 'wards', 'wise', 'y'
        }

    def P(self, word): 
        "Probability of `word`."
        N = sum(self.word_freq.values())
        return self.word_freq[word] / N if N > 0 else 0

    def correction(self, word): 
        "Most probable spelling correction for word."
        candidates_list = self.candidates(word)
        return max(candidates_list, key=self.P) if candidates_list else word

    def candidates(self, word): 
        "Generate possible spelling corrections for word."
        if word in self.word_set:
            return {word}
        
        # check affixes that match by default first!!
        affix_candidates = self.affixCheck(word)
        if affix_candidates:
            return affix_candidates
        
        # edit distance 1
        edit1_set = self.edits1(word)
        known_edit1 = self.known(edit1_set)
        if known_edit1:
            return known_edit1
        
        # affix handling on edit distance 1
        affix_edit1 = self.affixCheck2(edit1_set)
        if affix_edit1:
            return affix_edit1
        
        # edit distance 2
        edit2_set = self.edits2(edit1_set)
        known_edit2 = self.known(edit2_set)
        if known_edit2:
            return known_edit2
        
        # word unknown!!!
        return {word}

    def known(self, words): 
        "The subset of `words` that appear in the dictionary of word_set."
        return set(w for w in words if w in self.word_freq)

    def edits1(self, word):
        "All edits that are one edit away from `word`."
        letters    = 'abcdefghijklmnopqrstuvwxyz'
        splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]
        deletes    = [L + R[1:]               for L, R in splits if R]
        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]
        replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]
        inserts    = [L + c + R               for L, R in splits for c in letters]
    
        return set(deletes + transposes + replaces + inserts)

    def edits2(self, edits1_ls): 
        "All edits that are two edits away from `word`."
        return (e2 for e1 in edits1_ls for e2 in self.edits1(e1))
    
    def affixesCheck(self, edit1_ls):
        prefixes = [L + W for L in self.prefixes for W in edit1_ls]
        suffixes = [W + R for R in self.suffixes for W in edit1_ls]

        return set([W for W in edit1_ls] + prefixes + suffixes)
    
    def affixCheck(self, word):
        # Check prefixes
        for prefix in self.prefixes:
            if word.startswith(prefix):
                stem = word[len(prefix):]
                if stem in self.word_set and len(stem) > 2:  # Ensure stem is substantial
                    return {word}
        
        # Check suffixes
        for suffix in self.suffixes:
            if word.endswith(suffix):
                stem = word[:-len(suffix)]
                if stem in self.word_set and len(stem) > 2:  # Ensure stem is substantial
                    return {word}
        
        return set()
    
    def affixCheck2(self, edit_set):
        valid_candidates = set()
        
        for word in edit_set:
            # Check if this edit with affix handling leads to a valid word
            affixCandidates = self.affixCheck(word)
            if affixCandidates:
                valid_candidates.update(affixCandidates)
                
        return valid_candidates

